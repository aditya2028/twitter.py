{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+NctYChxPV7zlcrF40ohF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya2028/twitter.py/blob/main/twitterscraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import datetime\n",
        "\n",
        "tweets_df = pd.DataFrame()\n",
        "st.write(\"# Twitter data scraping\")\n",
        "option = st.selectbox('How would you like the data to be searched?',('Keyword', 'Hashtag'))\n",
        "word = st.text_input('Please enter a '+option, 'LIC Policy')\n",
        "start = st.date_input(\"Select the start date\", datetime.date(2022, 1, 1),key='d1')\n",
        "end = st.date_input(\"Select the end date\", datetime.date(2023, 1, 1),key='d2')\n",
        "tweet_c = st.slider('How many tweets to scrape', 0, 1000, 5)\n",
        "tweets_list = []\n",
        "\n",
        "# SCRAPE DATA USING TwitterSearchScraper\n",
        "if word:\n",
        "  for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{word} lang:en since:{start} until:{end}').get_items()):\n",
        "      if i>tweet_c-1:\n",
        "          break\n",
        "      tweets_list.append([ tweet.content, tweet.user.username, tweet.replyCount, tweet.retweetCount,tweet.likeCount ])\n",
        "  tweets_df = pd.DataFrame(tweets_list, columns=['Content', 'Username', 'ReplyCount', 'RetweetCount', 'LikeCount'])\n",
        "else:\n",
        "  for i,tweet in enumerate(sntwitter.TwitterHashtagScraper(f'{word} lang:en since:{start} until:{end}').get_items()):\n",
        "      if i>tweet_c-1:\n",
        "          break            \n",
        "      tweets_list.append([ tweet.content, tweet.user.username, tweet.replyCount, tweet.retweetCount,tweet.likeCount ])\n",
        "  tweets_df = pd.DataFrame(tweets_list, columns=['Content', 'Username', 'ReplyCount', 'RetweetCount', 'LikeCount'])\n",
        "\n",
        "\n",
        "#SIDEBAR\n",
        "with st.sidebar:   \n",
        "    st.info('DETAILS', icon=\"ℹ️\")\n",
        "    if option=='Keyword':\n",
        "        st.info('Keyword is '+word)\n",
        "    else:\n",
        "        st.info('Hashtag is '+word)\n",
        "    st.info('Starting Date is '+str(start))\n",
        "    st.info('End Date is '+str(end))\n",
        "    st.info(\"Number of Tweets \"+str(tweet_c))\n",
        "    st.info(\"Total Tweets Scraped \"+str(len(tweets_df)))\n",
        "    x=st.button('Show Tweets',key=1)\n",
        "\n",
        "# DOWNLOAD AS CSV\n",
        "@st.cache # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
        "def convert_df(df):    \n",
        "    return df.to_csv().encode('utf-8')\n",
        "\n",
        "if not tweets_df.empty:\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        csv = convert_df(tweets_df) # CSV\n",
        "        c=st.download_button(label=\"Download data as CSV\",data=csv,file_name='Twitter_data.csv',mime='text/csv',)        \n",
        "    with col2:    # JSON\n",
        "        json_string = tweets_df.to_json(orient ='records')\n",
        "        j=st.download_button(label=\"Download data as JSON\",file_name=\"Twitter_data.json\",mime=\"application/json\",data=json_string,)\n",
        "\n",
        "    with col3: # SHOW\n",
        "        y=st.button('Show Tweets',key=2)\n",
        "\n",
        "if c:\n",
        "    st.success(\"The Scraped Data is Downloaded as .CSV file:\",icon=\"✅\")  \n",
        "if j:\n",
        "    st.success(\"The Scraped Data is Downloaded as .JSON file\",icon=\"✅\")     \n",
        "if x: # DISPLAY\n",
        "    st.success(\"The Scraped Data is:\",icon=\"✅\")\n",
        "    st.write(tweets_df)\n",
        "if y: # DISPLAY\n",
        "    st.balloons()\n",
        "    st.success(\"Tweets Scraped Successfully:\",icon=\"✅\")\n",
        "    st.write(tweets_df)\n"
      ],
      "metadata": {
        "id": "-ydA6VwN_wjE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}